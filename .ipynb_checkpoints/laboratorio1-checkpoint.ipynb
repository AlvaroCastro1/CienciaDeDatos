{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "528ad3d1",
   "metadata": {},
   "source": [
    "## Explicación de Bibliotecas\n",
    "\n",
    "### 1. `pandas`\n",
    "`pandas` es una biblioteca de Python que generalmente se usa para la manipulacion y analisis de datos. Ademas, permite trabajar con `DataFrames`.\n",
    "\n",
    "**Ejemplo de uso:**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# crear un df\n",
    "data = {'Nombre': ['Ana', 'Juan', 'Pedro'], 'Edad': [23, 35, 29]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# imprimir las primeras 5 filas del df\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "### 2. `requests`\n",
    "`requests` es una biblioteca que permite realizar peticiones HTTP y se usa generalmente para pedir datos de APIs y procesarlos.\n",
    "\n",
    "**Ejemplo de uso:**\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "# realizar una peticion\n",
    "url = 'https://jsonplaceholder.typicode.com/users'\n",
    "respuesta = requests.get(url)\n",
    "\n",
    "# si la respuesta fue OK\n",
    "if respuesta.status_code == 200:\n",
    "    data = respuesta.json()\n",
    "    print(data)\n",
    "else:\n",
    "    print(f\"Error en la solicitud: {respuesta.status_code}\")\n",
    "```\n",
    "\n",
    "### 3. `sqlite3`\n",
    "`sqlite3` permite interactuar con bases de datos SQLite desde Python y facilita el manejo de BBDD sin la necesidad de configurar un servidor.\n",
    "\n",
    "**Ejemplo de uso:**\n",
    "\n",
    "```python\n",
    "import sqlite3\n",
    "\n",
    "# conexion a una bd\n",
    "conn = sqlite3.connect('mi_base_datos.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# crear una tabla\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS usuarios (id INTEGER PRIMARY KEY, nombre TEXT, edad INTEGER)''')\n",
    "cursor.execute(\"INSERT INTO usuarios (nombre, edad) VALUES ('Pedro', 30)\")\n",
    "\n",
    "# guardar los cambios\n",
    "conn.commit()\n",
    "# Consultar datos\n",
    "cursor.execute(\"SELECT * FROM usuarios\")\n",
    "print(cursor.fetchall())\n",
    "\n",
    "conn.close() # Cerrar la conexion\n",
    "```\n",
    "### 4. `beautifulsoup4`\n",
    "`beautifulsoup4` es utilizada para hacer web scraping, lo que significa extraer datos de sitios web al analizar y manipular elementos.\n",
    "\n",
    "**Ejemplo de uso:**\n",
    "\n",
    "```python\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# obtener contenido HTML de una pag web\n",
    "url = 'https://example.com'\n",
    "respuesta = requests.get(url)\n",
    "html_contenido = respuesta.content\n",
    "\n",
    "# se analiza el contenido HTML\n",
    "sopa = BeautifulSoup(html_contenido, 'html.parser')\n",
    "\n",
    "# se extrae el titulo\n",
    "titulo = sopa.title.string\n",
    "print(f\"Titulo de la pagina: {titulo}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26a04d1-aedc-4fff-a297-6ad56237e826",
   "metadata": {},
   "source": [
    "# Inicio del laboratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9adbb3ac-165f-4ff2-bb8f-f6a4b1d305b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in c:\\users\\hp245-user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\hp245-user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ucimlrepo) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in c:\\users\\hp245-user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ucimlrepo) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp245-user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp245-user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\hp245-user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\hp245-user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp245-user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\hp245-user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\dlib-19.24.99-py3.11-win-amd64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6357647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerias que se utilizaran\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38351fde",
   "metadata": {},
   "source": [
    "### Ejemplo de cómo cargar los datos de iris.data de UCI repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cfa1e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length  sepal width  petal length  petal width\n",
      "0           5.1          3.5           1.4          0.2\n",
      "1           4.9          3.0           1.4          0.2\n",
      "2           4.7          3.2           1.3          0.2\n",
      "3           4.6          3.1           1.5          0.2\n",
      "4           5.0          3.6           1.4          0.2\n"
     ]
    }
   ],
   "source": [
    "# se busca por el id correspondiente \n",
    "iris = fetch_ucirepo(id=53)   \n",
    "# se obtienen los respectivos datos y categorias\n",
    "X = iris.data.features \n",
    "y = iris.data.targets \n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d630a",
   "metadata": {},
   "source": [
    "### Importar el conjunto de datos iris desde un archivo local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77eb1df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width        class\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "# desde un archivo\n",
    "ruta = \"./datos/iris/iris.data\"\n",
    "# sin cabecera\n",
    "df_iris = pd.read_csv(ruta, header=None)\n",
    "# con nombres\n",
    "nombres = [\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\",\"class\"]\n",
    "df_iris.columns = nombres\n",
    "print(df_iris.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e959ea1",
   "metadata": {},
   "source": [
    "### Importar el conjunto de datos Bank Marketing desde un archivo local Bank marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08fba9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age           job  marital  education default  balance housing loan  \\\n",
      "0   58    management  married   tertiary      no     2143     yes   no   \n",
      "1   44    technician   single  secondary      no       29     yes   no   \n",
      "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
      "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
      "4   33       unknown   single    unknown      no        1      no   no   \n",
      "\n",
      "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
      "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
      "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
      "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
      "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
      "4  unknown    5   may       198         1     -1         0  unknown  no  \n"
     ]
    }
   ],
   "source": [
    "#aqui debe ir la ruta donde estan los datos\n",
    "ruta_bank = \"C:/Users/Hp245-User/Desktop/datos/bank_marketing/bank-full.csv\"\n",
    "df_bank = pd.read_csv(ruta_bank, delimiter=\";\")\n",
    "print(df_bank.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a797538b",
   "metadata": {},
   "source": [
    "### Obtener datos JSON desde una API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f44b6e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id              name   username                      email  \\\n",
      "0   1     Leanne Graham       Bret          Sincere@april.biz   \n",
      "1   2      Ervin Howell  Antonette          Shanna@melissa.tv   \n",
      "2   3  Clementine Bauch   Samantha         Nathan@yesenia.net   \n",
      "3   4  Patricia Lebsack   Karianne  Julianne.OConner@kory.org   \n",
      "4   5  Chelsey Dietrich     Kamren   Lucio_Hettinger@annie.ca   \n",
      "\n",
      "                                             address                  phone  \\\n",
      "0  {'street': 'Kulas Light', 'suite': 'Apt. 556',...  1-770-736-8031 x56442   \n",
      "1  {'street': 'Victor Plains', 'suite': 'Suite 87...    010-692-6593 x09125   \n",
      "2  {'street': 'Douglas Extension', 'suite': 'Suit...         1-463-123-4447   \n",
      "3  {'street': 'Hoeger Mall', 'suite': 'Apt. 692',...      493-170-9623 x156   \n",
      "4  {'street': 'Skiles Walks', 'suite': 'Suite 351...          (254)954-1289   \n",
      "\n",
      "         website                                            company  \n",
      "0  hildegard.org  {'name': 'Romaguera-Crona', 'catchPhrase': 'Mu...  \n",
      "1  anastasia.net  {'name': 'Deckow-Crist', 'catchPhrase': 'Proac...  \n",
      "2    ramiro.info  {'name': 'Romaguera-Jacobson', 'catchPhrase': ...  \n",
      "3       kale.biz  {'name': 'Robel-Corkery', 'catchPhrase': 'Mult...  \n",
      "4   demarco.info  {'name': 'Keebler LLC', 'catchPhrase': 'User-c...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# se establece la uri y se hace la solicitud\n",
    "url = 'https://jsonplaceholder.typicode.com/users'\n",
    "respuesta = requests.get(url)\n",
    "\"\"\"si la respuesta es OK o 200 se hace construye el df\n",
    "o simplemente se imprime el tipo de error\"\"\"\n",
    "if respuesta.status_code == 200:\n",
    "    data = respuesta.json()\n",
    "    df_jsonplaceholder = pd.DataFrame(data)\n",
    "    print(df_jsonplaceholder.head())\n",
    "else:\n",
    "    print(f\"Error al obtener los datos {respuesta.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23ee796",
   "metadata": {},
   "source": [
    "### Descargar y mostrar contenido de un libro desde Gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4665c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xef\\xbb\\xbfThe Project Gutenberg eBook of Fuente Ovejuna\\r\\n    \\r\\nThis ebook is for the use of anyone anywhere in the United States and\\r\\nmost other parts of the world at no cost and with almost no restrictions\\r\\nwhatsoever. You may copy it, give it away or re-use it under the terms\\r\\nof the Project Gutenberg License included with this ebook or online\\r\\nat www.gutenberg.org. If you are not located in the United States,\\r\\nyou will have to check the laws of the country where you are located\\r\\nbefore using this eB'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Nuevamente se hace la solicitud y se muestra si todo sale bien, caso contrario de avisa el status code\n",
    "status code !=200\n",
    "\"\"\"\n",
    "uri = \"https://www.gutenberg.org/cache/epub/60198/pg60198.txt\"\n",
    "respuesta_libro = requests.get(uri)\n",
    "if respuesta_libro.status_code == 200:\n",
    "    contenido = respuesta_libro.content\n",
    "    print(contenido[:500])  # Mostramos los primeros 500 caracteres del contenido\n",
    "else:\n",
    "    print(f\"Error al obtener el contenido: {respuesta_libro.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da35d6bd",
   "metadata": {},
   "source": [
    "### Crear un DataFrame de 10 libros del sitio Gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b994fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Texto  \\\n",
      "0  ﻿The Project Gutenberg eBook of Lukukammio\\r\\n...   \n",
      "1  ﻿The Project Gutenberg eBook of Tuonen ahventa...   \n",
      "2  ﻿The Project Gutenberg eBook of Beauty and the...   \n",
      "3  ﻿The Project Gutenberg eBook of Arthur's inher...   \n",
      "4  ﻿The Project Gutenberg eBook of Theology in ro...   \n",
      "\n",
      "                                              Título  \n",
      "0                                         Lukukammio  \n",
      "1                           Tuonen ahventa onkimassa  \n",
      "2  Beauty and the beast : An old tale new-told, w...  \n",
      "3                                           The Door  \n",
      "4      The Story of the Champions of the Round Table  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# primero busqué 10 libros con sus uris y titulos\n",
    "libros = {\n",
    "    \"https://www.gutenberg.org/cache/epub/74279/pg74279.txt\": \"Lukukammio\",\n",
    "    \"https://www.gutenberg.org/cache/epub/74278/pg74278.txt\": \"Tuonen ahventa onkimassa\",\n",
    "    \"https://www.gutenberg.org/cache/epub/74277/pg74277.txt\": \"Beauty and the beast : An old tale new-told, with pictures\",\n",
    "    \"https://www.gutenberg.org/cache/epub/74276/pg74276.txt\": \"The Door\",\n",
    "    \"https://www.gutenberg.org/cache/epub/74275/pg74275.txt\": \"The Story of the Champions of the Round Table\",\n",
    "    \"https://www.gutenberg.org/cache/epub/74274/pg74274.txt\": \"The Blue Balloon\",\n",
    "    \"https://www.gutenberg.org/cache/epub/74273/pg74273.txt\": \"The Invisible Man\",\n",
    "    \"https://www.gutenberg.org/cache/epub/74272/pg74272.txt\": \"The Black Cat\",\n",
    "    \"https://www.gutenberg.org/cache/epub/74271/pg74271.txt\": \"The Great Gatsby\",\n",
    "    \"https://www.gutenberg.org/cache/epub/74270/pg74270.txt\": \"Moby Dick\"\n",
    "}\n",
    "\n",
    "# por cada libro se hace su solicitud \n",
    "datos = []\n",
    "for url, title in libros.items():\n",
    "    response = requests.get(url)\n",
    "    # si fue exitoso añadimos el contenido a la lista de datos o el codigo de error\n",
    "    if response.status_code == 200:        \n",
    "        datos.append([response.text, title])\n",
    "    else:\n",
    "        datos.append([f\"Error {response.status_code}\", title])\n",
    "# al final solo queda añadir en el df añadir \n",
    "df_libros = pd.DataFrame(datos, columns=[\"Texto\", \"Título\"])\n",
    "print(df_libros.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66e763e",
   "metadata": {},
   "source": [
    "## Tipos de Datos Estructurados y No Estructurados\n",
    "\n",
    "### 1. Datos Estructurados\n",
    "Los **datos estructurados** son aquellos que están organizados en un formato predefinido y fácilmente interpretable por máquinas. Un ejemplo típico son las bases de datos relacionales, donde los datos se organizan en tablas con filas y columnas. Estos datos suelen tener un esquema fijo, como nombres de columnas y tipos de datos específicos (por ejemplo, enteros, cadenas de texto, etc.). \n",
    "\n",
    "### 2. Datos No Estructurados\n",
    "Los **datos no estructurados** no siguen un formato específico y, por lo tanto, son más difíciles de organizar, procesar y analizar. Estos incluyen archivos de texto, correos electrónicos, imágenes, videos, audios y publicaciones en redes sociales.\n",
    "\n",
    "## ¿Por qué es conveniente usar `pandas` para Ciencia de Datos?\n",
    "\n",
    "`pandas` es una de las bibliotecas más importantes ya que permite la manipulación de datos en Python.\n",
    "\n",
    "Una de sus principales caracteristicas son su alta **facilidad al usar** grandes volúmenes de datos. Pues el tipo `DataFrames` permiten manejar datos tabulares de manera eficiente y realizar operaciones complejas con poco código.\n",
    "Otra ventaje es que se pueden realizar **operaciones** como filtrar, agrupar, agregar y transformar datos. Lo que lo hace ideal para realizar análisis , preparar datos o manipular grandes conjuntos de datos de forma rápida.\n",
    "Y por ultimo se permite una gran cantidad de **formatos** ya que se puede leer y escribir datos desde/para una amplia gama de formatos, incluidos CSV, Excel, SQL, JSON, etc.\n",
    "\n",
    "## ¿Cómo se pueden leer datos desde diversas fuentes y tipos de archivos?\n",
    "\n",
    "`Pandas` generalmete tiene diversas formas de poder realizar la lectura de archivos diferentes y hasta ahora hemos visto la funcion que permite leer de uno de los formatos de datos más utilizados. Cargando archivos CSV utilizando `pd.read_csv()`, lo que convierte el archivo en un `DataFrame` para su manipulación.\n",
    "  \n",
    "```python\n",
    "df = pd.read_csv('archivo.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93937ceb-911d-4e39-8568-1607905ea446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
